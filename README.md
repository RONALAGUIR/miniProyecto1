# miniProyecto1
Arrastrar y Soltar Virtual usando el Seguimiento de Manos en Python

ğŸ–ï¸ Proyecto Drag & Drop con Gestos usando OpenCV + MediaPipe
Este proyecto permite interactuar con objetos en pantalla utilizando gestos de la mano detectados por la cÃ¡mara. Fue desarrollado con Python, y hace uso de MediaPipe para el seguimiento de la mano y OpenCV para el procesamiento de imagen. Los usuarios pueden "agarrar" y mover objetos virtuales como imÃ¡genes simplemente juntando los dedos Ã­ndice y pulgar.

ğŸ¯ Objetivo
Crear una interfaz accesible para personas, ideal como ejemplo de interacciÃ³n natural entre humanos y computadoras. El sistema permite:

Detectar gestos de la mano.

Agarrar y mover objetos arrastrables en pantalla.

Personalizar los objetos (por ejemplo, el logo de una universidad).

Funciona en tiempo real con una cÃ¡mara web.

ğŸ–¼ï¸ Ejemplo visual
En este caso se usÃ³ el logo de la Universidad Mariano GÃ¡lvez como uno de los objetos que se pueden mover en pantalla:


ğŸ“ Estructura del Proyecto
bash
Copiar
Editar
ğŸ“ proyecto_drag_drop/
â”‚
â”œâ”€â”€ main.py                # CÃ³digo principal del proyecto
â”œâ”€â”€ objeto.png             # Imagen 1 (objeto arrastrable: logo UMG)
â”œâ”€â”€ objeto1.png            # Imagen 2 (otro objeto arrastrable)
â””â”€â”€ README.md              # Este archivo
âœ… Requisitos
InstalÃ¡ los siguientes paquetes de Python antes de ejecutar el proyecto:

bash
Copiar
Editar
pip install opencv-python mediapipe numpy
Si no usÃ¡s entorno virtual, podÃ©s usar:

bash
Copiar
Editar
python -m pip install --upgrade pip
pip install -r requirements.txt
Nota: Si necesitÃ¡s usar TensorFlow u otros modelos IA mÃ¡s adelante, tambiÃ©n podÃ©s agregar:

bash
Copiar
Editar
pip install tensorflow
ğŸ§  Â¿CÃ³mo Funciona?
MediaPipe Hands detecta la mano y sus puntos clave en tiempo real.

El programa calcula la distancia entre el dedo pulgar e Ã­ndice.

Si estÃ¡n lo suficientemente cerca (ej. < 40 px), se considera un gesto de "agarre".

El objeto se mueve junto con la mano mientras ese gesto se mantiene.

Cuando se sueltan los dedos, el objeto queda en la nueva posiciÃ³n.

ğŸ“¦ Uso de ImÃ¡genes Personalizadas
PodÃ©s cambiar los objetos arrastrables simplemente reemplazando las imÃ¡genes:

U.png: Reemplazala con cualquier otro objeto que quieras mover.

Asegurate que las imÃ¡genes tengan transparencia (canal alfa) para que se vean bien (formato .png con fondo transparente).

â–¶ï¸ CÃ³mo Ejecutar
ColocÃ¡ las imÃ¡genes dentro del mismo directorio del script.

Asegurate que tu cÃ¡mara estÃ© conectada.

EjecutÃ¡ el script:

bash
Copiar
Editar
python main.py
MostrÃ¡ la mano frente a la cÃ¡mara, juntÃ¡ Ã­ndice y pulgar sobre el objetoâ€¦ Â¡y arrastralo!

ğŸ“Œ Consejos
Asegurate de tener buena iluminaciÃ³n para que la cÃ¡mara y MediaPipe detecten bien la mano.

PodÃ©s ajustar la distancia mÃ­nima de agarre (d < 40) si necesitÃ¡s mÃ¡s o menos precisiÃ³n.

Las imÃ¡genes deben tener dimensiones apropiadas (100x100, 150x150, etc.).

ğŸš€ Ideas Futuras
Detectar mÃºltiples manos.

AÃ±adir sonido al agarrar o soltar objetos.

Exportar este sistema para usarlo como interfaz en una app mÃ³vil.

Integrar con text-to-speech para personas con discapacidad visual.

ğŸ“ CrÃ©ditos
Desarrollado con â¤ usando Python, OpenCV y MediaPipe.

Imagen del logo: Universidad Mariano GÃ¡lvez de Guatemala.
